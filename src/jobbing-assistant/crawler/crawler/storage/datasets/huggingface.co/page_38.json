{"url": "https://huggingface.co/docs/diffusers/main/en/index", "title": "Diffusers", "text": "       Hugging Face        Models  Datasets  Spaces  Posts  Docs     Solutions   Pricing        Log In  Sign Up     Diffusers documentation  Diffusers     Diffusers   \ud83c\udfe1 View all docs AWS Trainium & Inferentia Accelerate Amazon SageMaker Argilla AutoTrain Bitsandbytes Chat UI Competitions Dataset viewer Datasets Diffusers Distilabel Evaluate Google TPUs Gradio Hub Hub Python Library Huggingface.js Inference API (serverless) Inference Endpoints (dedicated) Leaderboards Optimum PEFT Safetensors Sentence Transformers TRL Tasks Text Embeddings Inference Text Generation Inference Tokenizers Transformers Transformers.js timm   Search documentation    main v0.30.1 v0.29.2 v0.28.2 v0.27.2 v0.26.3 v0.25.1 v0.24.0 v0.23.1 v0.22.3 v0.21.0 v0.20.0 v0.19.3 v0.18.2 v0.17.1 v0.16.0 v0.15.0 v0.14.0 v0.13.0 v0.12.0 v0.11.0 v0.10.2 v0.9.0 v0.8.0 v0.7.0 v0.6.0 v0.5.1 v0.4.1 v0.3.0 v0.2.4  EN JA KO PT ZH          Get started    \ud83e\udde8 Diffusers  Quicktour  Effective and efficient diffusion  Installation    Tutorials    Overview  Understanding pipelines, models and schedulers  AutoPipeline  Train a diffusion model  Load LoRAs for inference  Accelerate inference of text-to-image diffusion models  Working with big models    Load pipelines and adapters    Load pipelines  Load community pipelines and components  Load schedulers and models  Model files and layouts  Load adapters  Push files to the Hub    Generative tasks    Unconditional image generation  Text-to-image  Image-to-image  Inpainting  Text or image-to-video  Depth-to-image    Inference techniques    Overview  Distributed inference with multiple GPUs  Merge LoRAs  Scheduler features  Pipeline callbacks  Reproducible pipelines  Controlling image quality  Prompt techniques    Advanced inference    Outpainting    Specific pipeline examples    Stable Diffusion XL  SDXL Turbo  Kandinsky  IP-Adapter  PAG  ControlNet  T2I-Adapter  Latent Consistency Model  Textual inversion  Shap-E  DiffEdit  Trajectory Consistency Distillation-LoRA  Stable Video Diffusion  Marigold Computer Vision    Training    Overview  Create a dataset for training  Adapt a model to a new task   Models    Methods     Accelerate inference and reduce memory    Speed up inference  Reduce memory usage  PyTorch 2.0  xFormers  Token merging  DeepCache  TGATE   Optimized model formats    JAX/Flax  ONNX  OpenVINO  Core ML    Optimized hardware    Metal Performance Shaders (MPS)  Habana Gaudi     Conceptual Guides    Philosophy  Controlled generation  How to contribute?  Diffusers' Ethical Guidelines  Evaluating Diffusion Models    Community Projects    Projects built with Diffusers    API     Main Classes    Loaders    Models    Pipelines    Schedulers    Internal classes     You are viewing main version, which requires installation from source . If you'd like\n\t\t\tregular pip install, checkout the latest stable version ( v0.30.1 ).   Join the Hugging Face community  and get access to the augmented documentation experience   Collaborate on models, datasets and Spaces   Faster examples with accelerated inference   Switch between documentation themes  Sign Up  to get started                    Diffusers  \ud83e\udd17 Diffusers is the go-to library for state-of-the-art pretrained diffusion models for generating images, audio, and even 3D structures of molecules. Whether you\u2019re looking for a simple inference solution or want to train your own diffusion model, \ud83e\udd17 Diffusers is a modular toolbox that supports both. Our library is designed with a focus on usability over performance , simple over easy , and customizability over abstractions .  The library has three main components:  State-of-the-art diffusion pipelines for inference with just a few lines of code. There are many pipelines in \ud83e\udd17 Diffusers, check out the table in the pipeline overview for a complete list of available pipelines and the task they solve.  Interchangeable noise schedulers for balancing trade-offs between generation speed and quality.  Pretrained models that can be used as building blocks, and combined with schedulers, for creating your own end-to-end diffusion systems.  Tutorials  Learn the fundamental skills you need to start generating outputs, build your own diffusion system, and train a diffusion model. We recommend starting here if you're using \ud83e\udd17 Diffusers for the first time!  How-to guides  Practical guides for helping you load pipelines, models, and schedulers. You'll also learn how to use pipelines for specific tasks, control how outputs are generated, optimize for inference speed, and different training techniques.  Conceptual guides  Understand why the library was designed the way it was, and learn more about the ethical guidelines and safety implementations for using the library.  Reference  Technical descriptions of how \ud83e\udd17 Diffusers classes and methods work.  <  >  Update on GitHub      Quicktour \u2192    Diffusers        "}